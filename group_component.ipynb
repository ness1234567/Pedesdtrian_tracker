{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules for the project.\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tracker using the Kalman filter.\n",
    "class Track:\n",
    "    \n",
    "    def __init__(self, tid, box, deleteCounter, visibleFrames):\n",
    "        self._id = tid # ID for tracker\n",
    "        self._box = box # Bounding box\n",
    "        self._prevPos = []\n",
    "        self._deleteCounter = deleteCounter # Variable to keep track of whether to delete or not\n",
    "        self._visibleFrames = visibleFrames # Variable to keep track of the visible frames\n",
    "        self._kalmanFilter = self.initialiseKalman() # Initialise a Kalman filter\n",
    "        self._show = False # Don't show the box unless it's been visible for more than a specified number of frames\n",
    "      \n",
    "    def getPrevPos(self):\n",
    "        return self._prevPos\n",
    "    \n",
    "    def appendPrevPos(self, coord):\n",
    "        self._prevPos.append(coord)\n",
    "        if(len(self._prevPos) > 15):\n",
    "            self._prevPos.pop(0)\n",
    "    \n",
    "    def getID(self):\n",
    "        return self._id\n",
    "    \n",
    "    def setID(self, num):\n",
    "        self._id = num\n",
    "        \n",
    "    def getShow(self):\n",
    "        return self._show\n",
    "        \n",
    "    def getBox(self):\n",
    "        return self._box\n",
    "        \n",
    "    def setBox(self, box):\n",
    "        self._box = box\n",
    "        \n",
    "    def getDeleteCounter(self):\n",
    "        return self._deleteCounter\n",
    "        \n",
    "    def setDeleteCounter(self, num):\n",
    "        self._deleteCounter = num\n",
    "        \n",
    "    def getVisibleFrames(self):\n",
    "        return self._visibleFrames\n",
    "        \n",
    "    def setVisibleFrames(self, num):\n",
    "        self._visibleFrames = num\n",
    "        if(self._visibleFrames >= 10):\n",
    "            self._show = True\n",
    "        \n",
    "    def getKalmanFilter(self):\n",
    "        return self._kalmanFilter\n",
    "    \n",
    "    # Initialise the Kalman filter using matrices.\n",
    "    def initialiseKalman(self):\n",
    "        \n",
    "        # Use discrete time unit of 1 between each frame.\n",
    "        KF = cv2.KalmanFilter(6,2)\n",
    "        KF.measurementMatrix = np.array([[1, 0, 0, 0, 0, 0],\\\n",
    "                                         [0, 1, 0, 0, 0, 0]], np.float32)\n",
    "        KF.transitionMatrix = np.array([[1, 0, 1, 0, 0.5, 0],\\\n",
    "                                        [0, 1, 0, 1, 0, 0.5],\\\n",
    "                                        [0, 0, 1, 0, 1, 0],\\\n",
    "                                        [0, 0, 0, 1, 0, 1],\\\n",
    "                                        [0, 0, 0, 0, 1, 0],\\\n",
    "                                        [0, 0, 0, 0, 0, 1],], np.float32)\n",
    "        # Q matrix.\n",
    "        KF.processNoiseCov = np.array([[0.05, 0, 0, 0, 0, 0],\\\n",
    "                                       [0, 0.05, 0, 0, 0, 0],\\\n",
    "                                       [0, 0, 0.075, 0, 0, 0],\\\n",
    "                                       [0, 0, 0, 0.075, 0, 0],\\\n",
    "                                       [0, 0, 0, 0, 0.0015, 0],\\\n",
    "                                       [0, 0, 0, 0, 0, 0.0015]], np.float32)\n",
    "        \n",
    "        return KF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts the next track.\n",
    "def predictTracks(tracks):\n",
    "    for track in tracks:\n",
    "        \n",
    "        # Get the current box for the tracker.\n",
    "        x, y, w, h = track.getBox()\n",
    "        \n",
    "        # Update track location.\n",
    "        track.appendPrevPos((int(x+w/2), int(y+h/2)))\n",
    "        \n",
    "        # Get the centroid of the current box.\n",
    "        measurement = np.array([[np.float32(x+w/2)], [np.float32(y+h/2)]])\n",
    "        \n",
    "        # Predict the next track.\n",
    "        predictedState = track.getKalmanFilter().predict()\n",
    "        \n",
    "        # Get the predictions and update the box.\n",
    "        Xc, Yc, Vx, Vy, Ax, Ay = predictedState\n",
    "        track.setBox([(Xc-w/2), (Yc-h/2), w, h])\n",
    "                \n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the detections.\n",
    "def matchDetections(boxes, tracks):\n",
    "    newDetections = []\n",
    "    matchedDetections = []\n",
    "    matchedTracks = []\n",
    "    unmatchedTracks = []\n",
    "    \n",
    "    nDetections = len(boxes)\n",
    "    nTracks = len(tracks)\n",
    "    \n",
    "    # Make a cost matrix of the boxes and tracks.\n",
    "    cost = np.zeros((nTracks, nDetections))\n",
    "    \n",
    "    # Calculate the Euclidean distance for each entry in the matrix.\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for track in tracks:\n",
    "        x, y, w, h = track.getBox()\n",
    "        pred_Xc = x+w/2\n",
    "        pred_Yc = y+h/2\n",
    "\n",
    "        for box in boxes:\n",
    "            x, y, w, h = box\n",
    "            centre_x = x+w/2\n",
    "            centre_y = y+h/2\n",
    "\n",
    "            cost[i, j] = math.sqrt((pred_Xc - centre_x)**2 + (pred_Yc - centre_y)**2)\n",
    "            j = j + 1\n",
    "            \n",
    "        j = 0\n",
    "        i = i + 1\n",
    "            \n",
    "    threshold = 50\n",
    "    \n",
    "    # Match lowest cost detection to track.\n",
    "    i = 0\n",
    "    for track in tracks:\n",
    "        minCost_t = np.amin(cost[i, :])\n",
    "        d_index = np.where(cost[i,:] == minCost_t)  \n",
    "        minCost_d = np.amin(cost[:, d_index])\n",
    "\n",
    "        if((minCost_t < threshold) and (minCost_t == minCost_d)):\n",
    "            matchedDetections.append(boxes[d_index])\n",
    "            matchedTracks.append((track, boxes[d_index]))\n",
    "            x,y,w,h = boxes[d_index][0]\n",
    "            measurement = np.array([[np.float32(x+w/2)], [np.float32(y+h/2)]])\n",
    "            track.getKalmanFilter().correct(measurement)\n",
    "        else:\n",
    "            unmatchedTracks.append(track)\n",
    "            \n",
    "        i = i + 1\n",
    "    \n",
    "    # Find all the newest detections.\n",
    "    for box in boxes:\n",
    "        if np.array(box[0]) not in  np.array(matchedDetections):\n",
    "            newDetections.append(box)\n",
    "    \n",
    "    return unmatchedTracks, matchedTracks, newDetections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign new centres for the tracks.\n",
    "def updateMatchedTracks(matchedTracks):\n",
    "    for track in matchedTracks:\n",
    "        \n",
    "        # Set the box.\n",
    "        track[0].setBox(track[1][0])\n",
    "        \n",
    "        # Reset track deleteCount.\n",
    "        track[0].setDeleteCounter(0)\n",
    "        \n",
    "        # Increment consecutive visible frames\n",
    "        track[0].setVisibleFrames(track[0].getVisibleFrames() + 1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the unmatched tracks.\n",
    "def updateUnmatchedTracks(unmatchedTracks):\n",
    "    for track in unmatchedTracks:\n",
    "        # Increment track deleteCounter.\n",
    "        track.setDeleteCounter(track.getDeleteCounter() + 1)\n",
    "        \n",
    "        # Increment consecutive visible frames.\n",
    "        track.setVisibleFrames(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete old tracks if they have not appeared.\n",
    "def deleteOldTracks(unmatchedTracks, tracks):\n",
    "    for track in unmatchedTracks:\n",
    "        if track.getDeleteCounter() == 15:\n",
    "            tracks.remove(track)\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new tracks for new detections.\n",
    "def createNewTracks(newDetections, tracks):\n",
    "    for detection in newDetections:\n",
    "        x, y, w, h = detection\n",
    "        t = Track(-1, detection, 0, 5)\n",
    "        t.getKalmanFilter().statePost = np.array([x+w/2, y+h/2, 0, 0, 0, 0], np.float32)\n",
    "        t.getKalmanFilter().statePre = np.array([x+w/2, y+h/2, 0, 0, 0, 0], np.float32)\n",
    "        tracks.append(t)\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect mouse click down and release for user input when drawing the rectangle.\n",
    "def onClick(event, x, y, flags, param):\n",
    "    global refPt\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        refPt.append((x,y))\n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        refPt.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the previous point and current point of the pedestrian is in the boundary.\n",
    "def inBoundary(x, y):\n",
    "    \n",
    "    # Get the coordinates of the rectangle.\n",
    "    global refPt\n",
    "    x1 = refPt[0][0]\n",
    "    y1 = refPt[0][1]\n",
    "    x2 = refPt[1][0]\n",
    "    y2 = refPt[1][1]   \n",
    "    \n",
    "    # If the x and y values shift inbetween boundaries, return True.\n",
    "    if (((x-x1)*(x-x2) <= 0) and ((y-y1)*(y-y2) <= 0)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load all the frames and resize for a larger frame.\n",
    "# frames = glob.glob(\"sequence/*.jpg\")\n",
    "# frames.sort()\n",
    "# frame_list = [cv2.resize(cv2.imread(img),(1280, 960)) for img in frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the size of the frame to make a video writer.\n",
    "# fps = 24\n",
    "# h, w = 960, 1280\n",
    "# video = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (w,h), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write every frame into the video and release the video.\n",
    "# for frame in frame_list:\n",
    "#     video.write(frame)\n",
    "# video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a HOG descriptor with a different nlevels parameter (less computational power).\n",
    "win_size = (64, 128)\n",
    "block_size =(16, 16)\n",
    "block_stride = (8, 8)\n",
    "cell_size = (8, 8)\n",
    "nbins = 9\n",
    "deriv_aperture = 1\n",
    "win_sigma = 4.\n",
    "histogram_norm_type = 0\n",
    "l2_hys_threshold = 2.0000000000000001e-01\n",
    "gamma_correction = 0\n",
    "nlevels = 5\n",
    "\n",
    "# Instantiate an instance of the descriptor.\n",
    "hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins, deriv_aperture, win_sigma, histogram_norm_type,\n",
    "    l2_hys_threshold, gamma_correction, nlevels)\n",
    "\n",
    "# Set the SVM detector to OpenCV's people detector (window size of 64x128).\n",
    "hog.setSVMDetector(hog.getDefaultPeopleDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Stores the trackers.\n",
    "tracks = []\n",
    "\n",
    "# Initialise tracker ID to 0.\n",
    "track_id = 0\n",
    "\n",
    "# Counter for people inside a box.\n",
    "enterCount = 0\n",
    "exitCount = 0\n",
    "\n",
    "# Reference point on window for user mouse click.\n",
    "refPt = []\n",
    "firstFrame = True\n",
    "\n",
    "# Get the recently made video and step through the frames.\n",
    "cap = cv2.VideoCapture('output.mp4')\n",
    "cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "cv2.setMouseCallback('frame', onClick)\n",
    "\n",
    "# Process the video frame by frame.\n",
    "while(True):\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "        \n",
    "    # Get the bounding box dimensions.\n",
    "    boxes, weights = hog.detectMultiScale(gray, winStride=(4, 4),padding=(8, 8), scale=1.15)\n",
    "    \n",
    "    # Predict the tracks for the new frame.\n",
    "    tracks = predictTracks(tracks)\n",
    "    \n",
    "    # Update all existing tracks inside the list of trackers.\n",
    "    unmatchedTracks, matchedTracks, newDetections = matchDetections(boxes, tracks)\n",
    "    updateMatchedTracks(matchedTracks)   \n",
    "    updateUnmatchedTracks(unmatchedTracks)\n",
    "    tracks = deleteOldTracks(unmatchedTracks, tracks)\n",
    "    tracks = createNewTracks(newDetections, tracks)\n",
    "    \n",
    "    if not firstFrame:\n",
    "        # Display the detected boxes in the colour picture.\n",
    "        for track in tracks:\n",
    "            if track.getShow() is True:\n",
    "\n",
    "                # If classifier decides to show a new pedestrian, allocate an ID for them.\n",
    "                if track.getID() == -1:\n",
    "                    track.setID(track_id)\n",
    "                    track_id = track_id + 1\n",
    "\n",
    "                # Get the box of the current tracker and set different colours for the boxes:\n",
    "                # Red: Detected but not counted as pedestrian.\n",
    "                # Blue: Purely prediction.\n",
    "                # Green: Pedestrian.\n",
    "                x, y, w, h = track.getBox()\n",
    "\n",
    "                if track in unmatchedTracks:\n",
    "                    color = (255, 0, 0)\n",
    "                else:\n",
    "                    color = (0, 255, 0)\n",
    "\n",
    "                for i in range(0,len(track.getPrevPos())-1):\n",
    "                    prevPoint = track.getPrevPos()[i]\n",
    "                    nextPoint = track.getPrevPos()[i+1]\n",
    "                    cv2.line(frame, prevPoint, nextPoint, (0, 255, 0), 4, 8, 0)\n",
    "                \n",
    "                Xc = int(x+w/2)\n",
    "                Yc = int(y+h/2)\n",
    "                cv2.line(frame, nextPoint, (Xc, Yc), (0, 255, 0), 4, 8, 0)\n",
    "                cv2.rectangle(frame, (int(x), int(y)), (int(x+w), int(y+h)), color, 2)\n",
    "                cv2.putText(frame, str(track.getID()), (int(x), int(y-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "                \n",
    "                # Keep track of people entering/leaving.\n",
    "                if inBoundary(Xc, Yc) and not inBoundary(nextPoint[0], nextPoint[1]):\n",
    "                    cv2.putText(frame, (\"ENTERING\"), (Xc, Yc), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "                    enterCount += 1\n",
    "                elif not inBoundary(Xc, Yc) and inBoundary(nextPoint[0], nextPoint[1]):\n",
    "                    cv2.putText(frame, (\"LEAVING\"), (Xc, Yc), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "                    exitCount += 1\n",
    "                else:\n",
    "                    pass\n",
    "                    \n",
    "            else:\n",
    "                if(track.getDeleteCounter() <= 1):\n",
    "                    x, y, w, h = track.getBox()\n",
    "                    cv2.rectangle(frame, (int(x), int(y)), (int(x+w), int(y+h)), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, 'Detected Point', (int(x), int(y-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "            \n",
    "            # Print relevant information.\n",
    "            cv2.putText(frame, f\"Pedestrians:\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"{track_id}\", (350, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"People entering box:\", (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"{enterCount}\", (350, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"People leaving box:\", (10, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"{exitCount}\", (350, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "            \n",
    "    else:        \n",
    "        cv2.imshow('frame',frame)\n",
    "        cv2.resizeWindow('frame', (960, 720))\n",
    "        key = cv2.waitKey(1)\n",
    "        if len(refPt) != 2: # q to quit.\n",
    "            cv2.waitKey(-1)\n",
    "        else:\n",
    "            firstFrame = False\n",
    "    \n",
    "    # Draw the user defined rectangle on the screen.\n",
    "    cv2.rectangle(frame, refPt[0], refPt[1], (255, 0, 255), 4)\n",
    "\n",
    "    # Display the resulting frame.\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.resizeWindow('frame', (960, 720))\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'): # q to quit.\n",
    "        break\n",
    "    if key == ord('p'):\n",
    "        cv2.waitKey(-1) # p to pause, press any key to play.\n",
    "\n",
    "# Free the video and destroy videos.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
